{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text::  2033\n"
     ]
    }
   ],
   "source": [
    "text = \"A him polymath in the true sense, Farhan Akhtar is known as a writer, singer, actor, director and a producer too \\\n",
    "The actor's career trajectory has always been one to look forward to, for the memorable characters he has always given \\\n",
    "and the projects that he has been a part of. Looking his dapper best on the cover of a leading magazine on their latest\\\n",
    "issue, 'Farhantastic' is totally a mood and we look it! The magazine writes, `Understated performances \\\n",
    "insane body transformations or the courage to always speak his mind. What makes Farhan Akhtar a consistent \\\n",
    "favourite amongst the fans?`, and righty so. Donning a beige floral printed day-suit with a casual round neck \\\n",
    "white t-shirt standing amidst lush greens, Farhan looks like a vision on the cover. With every character \\\n",
    "one has always seen Farhan bring insane body transformations, the best examples are Bhaag Milkha Bhaag and his \\\n",
    "upcoming, Toofaan. The actor has also always spoken his mind with his wordplay and they've always struck the right \\\n",
    "chord and stay in our hearts forever. Some of the best examples being Dil Dhadakne Do, Zindagi Na Milegi Dobara. \\\n",
    "With each project, the actors delivers something new and adds the Farhan element to it. For example, in Zindagi Na \\\n",
    "Milegi Dobara we saw his poetic side, Bhaag Milkha Bhaag, his dedication for becoming the perfect reel life 'Milkha'\\\n",
    "was just incredible. The actor's way of portrayals has always been something one looks forward to. Farhan always \\\n",
    "ensures that as an actor, he chooses his projects that he feels connected to instantly and with that attachment, the \\\n",
    "audiences are always able to enjoy his every performance. Farhan's performances, his dedication to give in everything \\\n",
    "to his roles and fearlessness of speaking his mind- hence, a word that describes him best is his own, `Farhantastic`.\\\n",
    "The fans are all excited and looking forward to seeing Farhan next in the sports drama titled 'Toofaan' which has \\\n",
    "already created a great thunder with its poster releases. The film is being produced by Excel Entertainment.\"\n",
    "\n",
    "print(\"Length of the text:: \",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords                                      # for stop words\n",
    "from nltk.tokenize import word_tokenize                                # for tokenization of text\n",
    "from nltk.stem.porter import PorterStemmer                             # for Lemmatization\n",
    "from nltk.stem.snowball import SnowballStemmer                         # for Lemmatization\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text after removing stop words::  255\n"
     ]
    }
   ],
   "source": [
    "# converting the text into token\n",
    "token = word_tokenize(text)\n",
    "\n",
    "# defining stopwords\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "new_text = []\n",
    "for word in token:\n",
    "    if word not in stop_words:\n",
    "        new_text.append(word)\n",
    "print(\"Length of the text after removing stop words:: \",len(new_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'polymath', 'true', 'sense', ',', 'Farhan', 'Akhtar', 'known', 'writer', ',', 'singer', ',', 'actor', ',', 'director', 'producer', 'The', 'actor', \"'s\", 'career', 'trajectory', 'always', 'one', 'look', 'forward', ',', 'memorable', 'character', 'always', 'given', 'project', 'part', '.', 'Looking', 'dapper', 'best', 'cover', 'leading', 'magazine', 'latestissue', ',', \"'Farhantastic\", \"'\", 'totally', 'mood', 'look', '!', 'The', 'magazine', 'writes', ',', '`', 'Understated', 'performance', 'insane', 'body', 'transformation', 'courage', 'always', 'speak', 'mind', '.', 'What', 'make', 'Farhan', 'Akhtar', 'consistent', 'favourite', 'amongst', 'fan', '?', '`', ',', 'righty', '.', 'Donning', 'beige', 'floral', 'printed', 'day-suit', 'casual', 'round', 'neck', 'white', 't-shirt', 'standing', 'amidst', 'lush', 'green', ',', 'Farhan', 'look', 'like', 'vision', 'cover', '.', 'With', 'every', 'character', 'one', 'always', 'seen', 'Farhan', 'bring', 'insane', 'body', 'transformation', ',', 'best', 'example', 'Bhaag', 'Milkha', 'Bhaag', 'upcoming', ',', 'Toofaan', '.', 'The', 'actor', 'also', 'always', 'spoken', 'mind', 'wordplay', \"'ve\", 'always', 'struck', 'right', 'chord', 'stay', 'heart', 'forever', '.', 'Some', 'best', 'example', 'Dil', 'Dhadakne', 'Do', ',', 'Zindagi', 'Na', 'Milegi', 'Dobara', '.', 'With', 'project', ',', 'actor', 'delivers', 'something', 'new', 'add', 'Farhan', 'element', '.', 'For', 'example', ',', 'Zindagi', 'Na', 'Milegi', 'Dobara', 'saw', 'poetic', 'side', ',', 'Bhaag', 'Milkha', 'Bhaag', ',', 'dedication', 'becoming', 'perfect', 'reel', 'life', \"'Milkha'was\", 'incredible', '.', 'The', 'actor', \"'s\", 'way', 'portrayal', 'always', 'something', 'one', 'look', 'forward', '.', 'Farhan', 'always', 'ensures', 'actor', ',', 'chooses', 'project', 'feel', 'connected', 'instantly', 'attachment', ',', 'audience', 'always', 'able', 'enjoy', 'every', 'performance', '.', 'Farhan', \"'s\", 'performance', ',', 'dedication', 'give', 'everything', 'role', 'fearlessness', 'speaking', 'mind-', 'hence', ',', 'word', 'describes', 'best', ',', '`', 'Farhantastic', '`', '.The', 'fan', 'excited', 'looking', 'forward', 'seeing', 'Farhan', 'next', 'sport', 'drama', 'titled', \"'Toofaan\", \"'\", 'already', 'created', 'great', 'thunder', 'poster', 'release', '.', 'The', 'film', 'produced', 'Excel', 'Entertainment', '.']\n"
     ]
    }
   ],
   "source": [
    "# Performing the lemmitization \n",
    "\n",
    "lem_wordnet = WordNetLemmatizer()\n",
    "token_wordnet = [lem_wordnet.lemmatize(word) for word in new_text]\n",
    "print(token_wordnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'polymath', 'true', 'sense', ',', 'Farhan', 'Akhtar', 'known', 'writer', ',', 'singer', ',', 'actor', ',', 'director', 'producer', 'The', 'actor', \"'s\", 'career', 'trajectory', 'always', 'one', 'look', 'forward', ',', 'memorable', 'characters', 'always', 'given', 'projects', 'part', '.', 'Looking', 'dapper', 'best', 'cover', 'leading', 'magazine', 'latestissue', ',', \"'Farhantastic\", \"'\", 'totally', 'mood', 'look', '!', 'The', 'magazine', 'writes', ',', '`', 'Understated', 'performances', 'insane', 'body', 'transformations', 'courage', 'always', 'speak', 'mind', '.', 'What', 'makes', 'Farhan', 'Akhtar', 'consistent', 'favourite', 'amongst', 'fans', '?', '`', ',', 'righty', '.', 'Donning', 'beige', 'floral', 'printed', 'day-suit', 'casual', 'round', 'neck', 'white', 't-shirt', 'standing', 'amidst', 'lush', 'greens', ',', 'Farhan', 'looks', 'like', 'vision', 'cover', '.', 'With', 'every', 'character', 'one', 'always', 'seen', 'Farhan', 'bring', 'insane', 'body', 'transformations', ',', 'best', 'examples', 'Bhaag', 'Milkha', 'Bhaag', 'upcoming', ',', 'Toofaan', '.', 'The', 'actor', 'also', 'always', 'spoken', 'mind', 'wordplay', \"'ve\", 'always', 'struck', 'right', 'chord', 'stay', 'hearts', 'forever', '.', 'Some', 'best', 'examples', 'Dil', 'Dhadakne', 'Do', ',', 'Zindagi', 'Na', 'Milegi', 'Dobara', '.', 'With', 'project', ',', 'actors', 'delivers', 'something', 'new', 'adds', 'Farhan', 'element', '.', 'For', 'example', ',', 'Zindagi', 'Na', 'Milegi', 'Dobara', 'saw', 'poetic', 'side', ',', 'Bhaag', 'Milkha', 'Bhaag', ',', 'dedication', 'becoming', 'perfect', 'reel', 'life', \"'Milkha'was\", 'incredible', '.', 'The', 'actor', \"'s\", 'way', 'portrayals', 'always', 'something', 'one', 'looks', 'forward', '.', 'Farhan', 'always', 'ensures', 'actor', ',', 'chooses', 'projects', 'feels', 'connected', 'instantly', 'attachment', ',', 'audiences', 'always', 'able', 'enjoy', 'every', 'performance', '.', 'Farhan', \"'s\", 'performances', ',', 'dedication', 'give', 'everything', 'roles', 'fearlessness', 'speaking', 'mind-', 'hence', ',', 'word', 'describes', 'best', ',', '`', 'Farhantastic', '`', '.The', 'fans', 'excited', 'looking', 'forward', 'seeing', 'Farhan', 'next', 'sports', 'drama', 'titled', \"'Toofaan\", \"'\", 'already', 'created', 'great', 'thunder', 'poster', 'releases', '.', 'The', 'film', 'produced', 'Excel', 'Entertainment', '.']\n"
     ]
    }
   ],
   "source": [
    "# Performing the lemmatization using Spacy\n",
    "\n",
    "lem_spacy = spacy.load('en_core_web_sm', parse = True, tag = True, entity = True)\n",
    "\n",
    "token_spacy = lem_spacy(str(new_text))\n",
    "print(token_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'polymath', 'true', 'sens', ',', 'farhan', 'akhtar', 'known', 'writer', ',', 'singer', ',', 'actor', ',', 'director', 'produc', 'the', 'actor', \"'s\", 'career', 'trajectori', 'alway', 'one', 'look', 'forward', ',', 'memor', 'charact', 'alway', 'given', 'project', 'part', '.', 'look', 'dapper', 'best', 'cover', 'lead', 'magazin', 'latestissu', ',', 'farhantast', \"'\", 'total', 'mood', 'look', '!', 'the', 'magazin', 'write', ',', '`', 'underst', 'perform', 'insan', 'bodi', 'transform', 'courag', 'alway', 'speak', 'mind', '.', 'what', 'make', 'farhan', 'akhtar', 'consist', 'favourit', 'amongst', 'fan', '?', '`', ',', 'righti', '.', 'don', 'beig', 'floral', 'print', 'day-suit', 'casual', 'round', 'neck', 'white', 't-shirt', 'stand', 'amidst', 'lush', 'green', ',', 'farhan', 'look', 'like', 'vision', 'cover', '.', 'with', 'everi', 'charact', 'one', 'alway', 'seen', 'farhan', 'bring', 'insan', 'bodi', 'transform', ',', 'best', 'exampl', 'bhaag', 'milkha', 'bhaag', 'upcom', ',', 'toofaan', '.', 'the', 'actor', 'also', 'alway', 'spoken', 'mind', 'wordplay', 've', 'alway', 'struck', 'right', 'chord', 'stay', 'heart', 'forev', '.', 'some', 'best', 'exampl', 'dil', 'dhadakn', 'do', ',', 'zindagi', 'na', 'milegi', 'dobara', '.', 'with', 'project', ',', 'actor', 'deliv', 'someth', 'new', 'add', 'farhan', 'element', '.', 'for', 'exampl', ',', 'zindagi', 'na', 'milegi', 'dobara', 'saw', 'poetic', 'side', ',', 'bhaag', 'milkha', 'bhaag', ',', 'dedic', 'becom', 'perfect', 'reel', 'life', \"milkha'wa\", 'incred', '.', 'the', 'actor', \"'s\", 'way', 'portray', 'alway', 'someth', 'one', 'look', 'forward', '.', 'farhan', 'alway', 'ensur', 'actor', ',', 'choos', 'project', 'feel', 'connect', 'instant', 'attach', ',', 'audienc', 'alway', 'abl', 'enjoy', 'everi', 'perform', '.', 'farhan', \"'s\", 'perform', ',', 'dedic', 'give', 'everyth', 'role', 'fearless', 'speak', 'mind-', 'henc', ',', 'word', 'describ', 'best', ',', '`', 'farhantast', '`', '.the', 'fan', 'excit', 'look', 'forward', 'see', 'farhan', 'next', 'sport', 'drama', 'titl', 'toofaan', \"'\", 'alreadi', 'creat', 'great', 'thunder', 'poster', 'releas', '.', 'the', 'film', 'produc', 'excel', 'entertain', '.']\n"
     ]
    }
   ],
   "source": [
    "# Performing Stemming on the text\n",
    "\n",
    "stem_porter = PorterStemmer()\n",
    "stem_snowball = SnowballStemmer('english')\n",
    "token_porter = [stem_porter.stem(word) for word in new_text]\n",
    "token_snowball = [stem_snowball.stem(word) for word in new_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Converting the data into matrix form\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "text_vec = vectorizer.fit_transform(new_text)\n",
    "\n",
    "#print(vectorizer.vocabulary_)            # Changing text into a dictionary\n",
    "print(text_vec.todense())                 # Chacnging text into a matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wordplay', 'example', 'Na', 'righty', 'look', 'characters', 'The', 'element', ',', 'stay', 'already', 'character', 'standing', 'performances', 'Bhaag', 'vision', 'life', 'bring', 'singer', 'one', 'magazine', \"'\", 'seeing', 'give', 'dapper', 'Entertainment', 'writer', 'A', 'mood', 'Farhan', '.', 'Understated', 'Dobara', 'fearlessness', 'insane', 'trajectory', '!', 'struck', 'performance', 'producer', 'perfect', 'every', 'new', 'Some', 'printed', 'lush', 'amidst', 'Toofaan', 'actor', 'For', 'side', 'right', 'speaking', 'saw', 'part', 'everything', 'projects', 'Zindagi', 'able', 'upcoming', 'describes', 'excited', 'given', 'looks', 'known', 'examples', \"'Farhantastic\", 'poetic', 'Looking', 'beige', 'day-suit', 'adds', 'produced', 'With', 'transformations', 'amongst', 'neck', 'like', 'chord', 'becoming', 'project', 'Donning', 'forward', 'instantly', 'way', 'true', 'white', 'also', 'What', '.The', 'something', 'sports', 'round', 'polymath', 'Milegi', 'hearts', 'connected', 'portrayals', 'ensures', 'casual', 'Dil', 'favourite', '?', 'leading', 'director', 'cover', '`', 'actors', 'Dhadakne', 'created', 'always', 'Excel', 'releases', 'career', 'floral', 'seen', 'speak', 'Milkha', 'makes', 'totally', 't-shirt', 'audiences', 'film', 'thunder', 'incredible', 'Farhantastic', 'greens', 'delivers', 'poster', 'great', 'dedication', 'consistent', 'spoken', 'Do', 'word', \"'ve\", \"'s\", 'sense', \"'Milkha'was\", 'hence', 'reel', 'attachment', \"'Toofaan\", 'fans', 'enjoy', 'titled', 'latestissue', 'best', 'next', 'mind', 'roles', 'forever', 'body', 'mind-', 'writes', 'memorable', 'courage', 'Akhtar', 'chooses', 'drama', 'feels', 'looking']\n"
     ]
    }
   ],
   "source": [
    "# Building our vocabulary\n",
    "\n",
    "set_of_words = set()\n",
    "string = str(' '.join(new_text))               #Changing list into a string\n",
    "for words in string.split():                   # Splitting the string to iterate over it\n",
    "    set_of_words.add(words)\n",
    "vocab = list(set_of_words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'wordplay', 1: 'example', 2: 'Na', 3: 'righty', 4: 'look', 5: 'characters', 6: 'The', 7: 'element', 8: ',', 9: 'stay', 10: 'already', 11: 'character', 12: 'standing', 13: 'performances', 14: 'Bhaag', 15: 'vision', 16: 'life', 17: 'bring', 18: 'singer', 19: 'one', 20: 'magazine', 21: \"'\", 22: 'seeing', 23: 'give', 24: 'dapper', 25: 'Entertainment', 26: 'writer', 27: 'A', 28: 'mood', 29: 'Farhan', 30: '.', 31: 'Understated', 32: 'Dobara', 33: 'fearlessness', 34: 'insane', 35: 'trajectory', 36: '!', 37: 'struck', 38: 'performance', 39: 'producer', 40: 'perfect', 41: 'every', 42: 'new', 43: 'Some', 44: 'printed', 45: 'lush', 46: 'amidst', 47: 'Toofaan', 48: 'actor', 49: 'For', 50: 'side', 51: 'right', 52: 'speaking', 53: 'saw', 54: 'part', 55: 'everything', 56: 'projects', 57: 'Zindagi', 58: 'able', 59: 'upcoming', 60: 'describes', 61: 'excited', 62: 'given', 63: 'looks', 64: 'known', 65: 'examples', 66: \"'Farhantastic\", 67: 'poetic', 68: 'Looking', 69: 'beige', 70: 'day-suit', 71: 'adds', 72: 'produced', 73: 'With', 74: 'transformations', 75: 'amongst', 76: 'neck', 77: 'like', 78: 'chord', 79: 'becoming', 80: 'project', 81: 'Donning', 82: 'forward', 83: 'instantly', 84: 'way', 85: 'true', 86: 'white', 87: 'also', 88: 'What', 89: '.The', 90: 'something', 91: 'sports', 92: 'round', 93: 'polymath', 94: 'Milegi', 95: 'hearts', 96: 'connected', 97: 'portrayals', 98: 'ensures', 99: 'casual', 100: 'Dil', 101: 'favourite', 102: '?', 103: 'leading', 104: 'director', 105: 'cover', 106: '`', 107: 'actors', 108: 'Dhadakne', 109: 'created', 110: 'always', 111: 'Excel', 112: 'releases', 113: 'career', 114: 'floral', 115: 'seen', 116: 'speak', 117: 'Milkha', 118: 'makes', 119: 'totally', 120: 't-shirt', 121: 'audiences', 122: 'film', 123: 'thunder', 124: 'incredible', 125: 'Farhantastic', 126: 'greens', 127: 'delivers', 128: 'poster', 129: 'great', 130: 'dedication', 131: 'consistent', 132: 'spoken', 133: 'Do', 134: 'word', 135: \"'ve\", 136: \"'s\", 137: 'sense', 138: \"'Milkha'was\", 139: 'hence', 140: 'reel', 141: 'attachment', 142: \"'Toofaan\", 143: 'fans', 144: 'enjoy', 145: 'titled', 146: 'latestissue', 147: 'best', 148: 'next', 149: 'mind', 150: 'roles', 151: 'forever', 152: 'body', 153: 'mind-', 154: 'writes', 155: 'memorable', 156: 'courage', 157: 'Akhtar', 158: 'chooses', 159: 'drama', 160: 'feels', 161: 'looking'}\n"
     ]
    }
   ],
   "source": [
    "# Fetching the position/index of each token in the vocabulary\n",
    "\n",
    "position = {}\n",
    "\n",
    "for pos, word in enumerate(vocab):\n",
    "    position[pos] = word\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix = np.zeros((len(new_text), len(vocab)))\n",
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.297002997002997, subjectivity=0.5845612720612721)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the sentiment of the text\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "TextBlob(string).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.08821021571021574, subjectivity=0.4667772351105685)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.019, 'neu': 0.825, 'pos': 0.155, 'compound': 0.9942}\n",
      "{'neg': 0.025, 'neu': 0.778, 'pos': 0.198, 'compound': 0.9942}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "print(analyser.polarity_scores(text))\n",
    "print(analyser.polarity_scores(' '.join(new_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'actor', 'actors', 'adds', 'akhtar', 'already', 'also', 'always', 'amidst', 'amongst', 'attachment', 'audiences', 'becoming', 'beige', 'best', 'bhaag', 'body', 'bring', 'career', 'casual', 'character', 'characters', 'chooses', 'chord', 'connected', 'consistent', 'courage', 'cover', 'created', 'dapper', 'day', 'dedication', 'delivers', 'describes', 'dhadakne', 'dil', 'director', 'do', 'dobara', 'donning', 'drama', 'element', 'enjoy', 'ensures', 'entertainment', 'every', 'everything', 'example', 'examples', 'excel', 'excited', 'fans', 'farhan', 'farhantastic', 'favourite', 'fearlessness', 'feels', 'film', 'floral', 'for', 'forever', 'forward', 'give', 'given', 'great', 'greens', 'hearts', 'hence', 'incredible', 'insane', 'instantly', 'known', 'latestissue', 'leading', 'life', 'like', 'look', 'looking', 'looks', 'lush', 'magazine', 'makes', 'memorable', 'milegi', 'milkha', 'mind', 'mood', 'na', 'neck', 'new', 'next', 'one', 'part', 'perfect', 'performance', 'performances', 'poetic', 'polymath', 'portrayals', 'poster', 'printed', 'produced', 'producer', 'project', 'projects', 'reel', 'releases', 'right', 'righty', 'roles', 'round', 'saw', 'seeing', 'seen', 'sense', 'shirt', 'side', 'singer', 'some', 'something', 'speak', 'speaking', 'spoken', 'sports', 'standing', 'stay', 'struck', 'suit', 'the', 'thunder', 'titled', 'toofaan', 'totally', 'trajectory', 'transformations', 'true', 'understated', 'upcoming', 've', 'vision', 'was', 'way', 'what', 'white', 'with', 'word', 'wordplay', 'writer', 'writes', 'zindagi']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
